class Neuron:
    def __init__(self, input_size, id, learning_rate=0.2, convergence_criteria=0.3):
        self.id = id
        # Initialize the weights with zeros. The number of weights is equal to the input size.
        self.weights = [0] * input_size

        # Initialize the bias with 0.0.
        self.bias = 0.0

        # Set the learning rate, which determines the step size in weight updates during training.
        # Default value is 0.2 if not specified.
        self.learning_rate = learning_rate

        # Set the convergence criteria, which determines when to stop training if the error is small enough.
        # Default value is 0.1 if not specified.
        self.convergence_criteria = convergence_criteria

    def activation(self, z):
        if z > 1:
            return 1
        else:
            return 0

    def preditciton(self, feature_vector: list[int]):
        # Initialize the weighted sum
        weighted_sum = 0.0

        # Calculate the weighted sum by multiplying each feature with its corresponding weight
        for i in range(len(feature_vector)):
            weighted_sum += feature_vector[i] * self.weights[i]

        # Pass the weighted sum through the activation function to get the output (0 or 1)
        output = self.activation(weighted_sum)
        return output


    def train(self, input_data, labels):
        epochs = 50
        numerical_labels = [0 if label == 'spam' else 1 for label in labels]

        for i in range(0, epochs):
            # check if any changes in the learning have been made
            check_weight_bias_update = False

            # looping thorugh each feature vector
            for feature_vector, label in zip(input_data, numerical_labels):

                # calculating weighted_sum
                weighted_sum = self.preditciton(feature_vector)

                # checking if neuron is about to get activated
                isActive = self.activation(weighted_sum)

                # Comparing label and predicted output
                error_calc = 0
                if weighted_sum == label:
                    print("Prediction is valid")
                else:
                    print("Prediction is invalid")
                    error_calc = label - weighted_sum

                # updating weights
                """
                w - represents each weight value in the self.weights list, which corresponds to a specific feature.
                x - represents each feature value in the feature_vector, which corresponds to the feature value for the specific weight.
                The zip() function is used to combine elements from two or more iterables (in this case, self.weights and feature_vector) into pairs of elements.
                It creates an iterator that generates tuples containing the corresponding elements from each iterable.
                """
                if isActive == 1:
                    self.weights = [w + self.learning_rate * error_calc * x for w, x in
                                    zip(self.weights, feature_vector)]
                else:
                    self.weights = [w - self.learning_rate * error_calc * x for w, x in
                                    zip(self.weights, feature_vector)]

                # updating bias
                self.bias += self.learning_rate * error_calc
